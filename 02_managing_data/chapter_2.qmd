---
title: "chapter 2, Managing & Understanding Data"
author: "jason grahn"
format: gfm
editor: visual
output: "asis"
---

## Chapter 2

```{r}
library(tidyverse)
```

```{r}
subject_name <- c("John Doe", "Jane Doe", "Steve Graves")
temperature <- c(98.1, 98.6, 101.4)
flu_status <- c(FALSE, FALSE, TRUE)

fever <- temperature > 100
subject_name[fever]

gender <- factor(c("MALE", "FEMALE", "MALE"))

blood <- factor(c("O", "AB", "A"),
                levels = c("A", "B", "AB", "O"))
blood

symptoms <- factor(c("SEVERE", "MILD", "MODERATE"),
                   levels = c("MILD", "MODERATE", "SEVERE"),
                   ordered = TRUE)

# make it a list
subject1 <- list(fullname = subject_name[1],
                 temperature = temperature[1],
                 flu_status = flu_status[1],
                 gender = gender[1],
                 blood = blood[1],
                 symptoms = symptoms[1])

#make it a DF
pt_data <- data.frame(subject_name, temperature, flu_status, gender, blood, symptoms)

pt_data
```

Of course, columns are better accessed by name rather than position, and negative signs can be used to exclude rows or columns of data. Therefore, the output of the command:

```{r}
pt_data[c(1, 3), c("temperature", "gender")]
```

... Is the same as...

```{r}
pt_data |> 
    filter(str_detect(subject_name, 'Doe') == TRUE) %>% 
    select(temperature, gender) 

```

adding a new column to a data frame

```{r}
pt_data$temp_c <- (pt_data$temperature - 32) * (5 / 9)

# is the same as 

pt_data %>% 
    mutate(temp_c = (temperature - 32) * (5/9))

```

# Matrices and arrays

```{r}
m <- matrix(c(1, 2, 3, 4), nrow = 2)
m

```

```{r}
save(pt_data, file = "mydata.RData")

load("mydata.RData")

#saveRDS(my_model, file = "my_model.rds")
ls()

#rm(m, subject1)

ls()
```

# Importing and saving datasets from CSV files

importing is pretty easy in both standard and tidy formats

```{r}
pt_data <- read.csv(here::here("02_managing_data", "data", "pt_data.csv"),
                    stringsAsFactors = TRUE)

pt_data_tidy <- read_csv(here::here("02_managing_data", "data", "pt_data.csv")) %>% 
    janitor::clean_names()

pt_data_tidy
```

writing..

```{r}
write.csv(pt_data, file = here::here("02_managing_data", "data", "pt_data_write.csv"), 
          row.names = FALSE)

write_csv(pt_data_tidy, file = here::here("02_managing_data", "data", "pt_data_tidy.csv"))
```

# Exploring and understanding data

using the **"usedcars.csv"** dataset..

```{r}
used_cars_tidy <- read_csv(here::here("02_managing_data", "data", "usedcars.csv")) %>% 
    janitor::clean_names()
```

## exploring the structure

```{r}
glimpse(used_cars_tidy)
```

The book uses base R "summary" but I like the `psych::describe` function a lot more for doing the same thing.

```{r}
summary(used_cars_tidy)
psych::describe(used_cars_tidy) 
```

more specific now..

```{r}
summary(used_cars_tidy[c("price", "mileage")])

used_cars_tidy %>% 
    select(price, mileage) %>% 
    psych::describe()
```

```{r}
range(used_cars_tidy$price)

# or again we can use describe, but describe doesn't like working with just 1 variable! 

used_cars_tidy %>% 
    select(price, year) %>% 
    psych::describe()

```

Combining range() with the difference function diff() allows you to compute the range statistic with a single line of code:

```{r}
diff(range(used_cars_tidy$price))
```

But we could have achieved the same results from looking at the `range` variable within psych::describe...

We dont get the Interquartile range of `price` from describe though, not without calculating it.

```{r}
IQR(used_cars_tidy$price)
```

```{r}
quantile(used_cars_tidy$price)
```

or we can supply arguments to get specific percentiles...

```{r}
quantile(used_cars_tidy$price, probs = c(0.01, 0.99))

# and in tidy format..

used_cars_tidy %>% 
    select(price) %>% 
    summarize(p01 = quantile(price,.01),
              p99 = quantile(price,.99))
```

and they emphasize sequencing, which, to be fair, i should do more often. Directly Replicating the base-R quantile process in Tidy doesn't look great. There's probably a better way to do this?

```{r}
quantile(used_cars_tidy$price, seq(from = 0, 
                                   to = 1, 
                                   by = .20))

used_cars_tidy %>% 
    select(price) %>% 
    summarize(percentiles = quantile(price,
                                     seq(from = 0, 
                                         to = 1, 
                                         by = .20)))

```

Oh.. this is MUCH better: https://stackoverflow.com/questions/30488389/using-dplyr-window-functions-to-calculate-percentiles.

```{r}
used_cars_tidy %>% 
    summarize(enframe(quantile(price, seq(from = 0, to = 1, by = .20)), "quantile", "price"))
```

# Visualizing numeric features -- boxplots

I dont particularly like the base R boxplots, so this will be interesting.

```{r}
boxplot(used_cars_tidy$price, 
        main = "Boxplot of Used Car Prices",
        ylab = "Price ($)")
boxplot(used_cars_tidy$mileage, 
        main = "Boxplot of Used Car Mileage",
        ylab = "Odometer (mi.)")

used_cars_tidy %>% 
    select(price, mileage) %>% 
    pivot_longer(names_to = "key",
                 values_to = "values",
                 cols = 1:2) %>% 
    mutate(box_labels = case_when(key == 'mileage' ~ 'Plot of Used Car Mileage (mi.)',
                                  key == 'price' ~ 'Plot of Used Car Price ($)')) %>% 
    ggplot(aes(y = values)) + 
    geom_boxplot() + 
    facet_wrap(~box_labels,
               scales = 'free_y') + 
    theme_light() + 
    theme(axis.title.x=element_blank(),
          axis.text.x=element_blank(),
          axis.ticks.x=element_blank()) + 
    labs(y = "")
    
```

This chapter goes on to talk about histograms, skewness, variance, standard deviations, and other base statistics.

Then we talk about building scatterplots to evaluate relationships between variables. Then we get into using the `gmodels` package to evaluate the strength of those relationships.

# Examining relationships -- two-way cross-tabulations

```{r}
library(gmodels)
```

```{r}
used_cars_tidy <- 
    used_cars_tidy %>% 
    mutate(conservative = color %in% c("Black", "Gray", "Silver", "White"))
```

```{r}
table(used_cars_tidy$conservative)
```

```{r}
gmodels::CrossTable(x = used_cars_tidy$model, y = used_cars_tidy$conservative)
```

The book says to add up all the chi-square contributions to do a fit test. Sure, though I'm sure there's a *better* way out there somewhere. Anyway.

```{r}
chi_sq <- 0.009 + .004 + .086 +.044 + .007 + 0.004
chi_sq

pch <- pchisq(chi_sq, df = 2, lower.tail = FALSE)
pch
# which matches the book. 
```

```{r}
CrossTable(x = used_cars_tidy$model, y = used_cars_tidy$conservative, chisq = TRUE)
```
